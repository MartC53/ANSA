{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Naming Convention\n",
    "\n",
    "Each `.pt` file should follow this format:\n",
    "\n",
    "```\n",
    "<label>_<replicate>.pt\n",
    "```\n",
    "\n",
    "**Examples:**\n",
    "- `150_1.pt` → Label: 150 (undetectable), Replicate: 1\n",
    "- `500_2.pt` → Label: 500 (low), Replicate: 2\n",
    "- `7000_3.pt` → Label: 7000 (medium), Replicate: 3\n",
    "- `20000_5.pt` → Label: 20000 (high), Replicate: 5\n",
    "\n",
    "\n",
    "\n",
    "## Class Definitions for Semi-Quantitative approach \n",
    "\n",
    "Infers clinical decision-making based on viral load counts (assuming 1:1 sample prep\n",
    ")\n",
    "1. `undetectable` → Label values `< 200`\n",
    "2. `low` → Label values `200 ≤ label ≤ 1000`\n",
    "3. `medium` → Label values `1000 < label ≤ 10000`\n",
    "4. `high` → Label values `> 10000`\n",
    "\n",
    "# Dataset Folder Structure\n",
    "\n",
    "Dataset is organized into the following structure to ensure proper training, validation, and testing:\n",
    "\n",
    "```\n",
    "Datasets/\n",
    "│-- Split/\n",
    "│   │-- Training/             # Training dataset (60% of total data)\n",
    "│   │   ├── undetectable/      # Class 0 (e.g., files with labels < 200)\n",
    "│   │   │   ├── 20_1.pt\n",
    "│   │   │   ├── 40_3.pt\n",
    "│   │   │   └── ...\n",
    "│   │   ├── low/               # Class 1 (200 ≤ label ≤ 1000)\n",
    "|   |   |   ├── 300_2.pt\n",
    "│   │   │   ├── 600_4.pt\n",
    "│   │   │   └── ...\n",
    "│   │   ├── medium/            # Class 2 (1000 < label ≤ 10000)\n",
    "│   │   │   ├── 2000_1.pt\n",
    "│   │   │   ├── 7000_2.pt\n",
    "│   │   │   └── ...\n",
    "│   │   ├── high/              # Class 3 (label > 10000)\n",
    "│   │   │   ├── 10000_2.pt\n",
    "│   │   │   ├── 90000_2.pt\n",
    "│   │   │   └── ...\n",
    "│\n",
    "│   │-- Validation/            # Validation dataset (20% of total data)\n",
    "│   │   ├── undetectable/\n",
    "│   │   │   ├── 20_2.pt\n",
    "│   │   │   ├── 40_4.pt\n",
    "│   │   │   └── ...\n",
    "│   │   ├── low/\n",
    "│   │   ├── medium/\n",
    "│   │   ├── high/\n",
    "│\n",
    "│   │-- Testing/               # Testing dataset (20% of total data)\n",
    "│   │   ├── undetectable/\n",
    "│   │   │   ├── 30_1.pt\n",
    "│   │   │   ├── 50_2.pt\n",
    "│   │   │   └── ...\n",
    "│   │   ├── low/\n",
    "│   │   ├── medium/\n",
    "│   │   ├── high/\n",
    "│\n",
    "│-- torch_tensors/              # Original .pt files before splitting\n",
    "│   │   ├── 100_1.pt\n",
    "│   │   ├── 200_3.pt\n",
    "│   │   ├── 5000_2.pt\n",
    "│   │   ├── 15000_4.pt\n",
    "│   │   └── ...\n",
    "```\n",
    "\n",
    "## Folder Descriptions\n",
    "\n",
    "- **`Training/`** – Used to train the model (60% of total data).\n",
    "- **`Validation/`** – Used to validate the model during training (20% of total data).\n",
    "- **`Testing/`** – Used to evaluate the model after training (20% of total data).\n",
    "- **`torch_tensors/`** – Stores the original `.pt` files before they were split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced image HxW from 500x500 to 224x224 to inprove speed for intial test \n",
    "class PTDataset(Dataset):\n",
    "    def __init__(self, root_dir, target_size=(224, 224), transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Path to the dataset directory (e.g., Training folder).\n",
    "            target_size (tuple): Desired output size (height, width).\n",
    "            transform (callable, optional): Optional transformations.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.target_size = target_size\n",
    "        self.transform = transform\n",
    "        self.classes = ['undetectable', 'low', 'medium', 'high']\n",
    "        \n",
    "        # Collect all file paths and labels\n",
    "        self.file_list = []\n",
    "        for label in self.classes:\n",
    "            class_path = os.path.join(root_dir, label)\n",
    "            for file in os.listdir(class_path):\n",
    "                if file.endswith('.pt'):\n",
    "                    self.file_list.append((os.path.join(class_path, file), self.classes.index(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.file_list[idx]\n",
    "\n",
    "        # Load the tensor from file\n",
    "        tensor_data = torch.load(file_path, weights_only=True)  # Shape [C, T, H, W]\n",
    "\n",
    "        # Ensure the tensor has enough frames\n",
    "        max_frames = tensor_data.shape[1]  \n",
    "        # Frame selection with safe index handling\n",
    "        selected_frame_indices = [69, 89, 109, 129, 149, 179] #Still need to plot average sigmoidal curve for better channels\n",
    "        selected_frame_indices = [i for i in selected_frame_indices if i < max_frames]\n",
    "\n",
    "        if len(selected_frame_indices) < 6:\n",
    "            raise ValueError(f\"Not enough frames in {file_path}, available: {max_frames}, required: 180\")\n",
    "\n",
    "        # Extract the required frames safely\n",
    "        avg_first_20 = torch.mean(tensor_data[:, :20, :, :], dim=1, keepdim=True)  # Shape [C, 1, H, W]\n",
    "        selected_frames = tensor_data[:, selected_frame_indices, :, :]  # Shape [C, 6, H, W]\n",
    "\n",
    "        # Concatenate to form a 7-channel tensor\n",
    "        final_tensor = torch.cat((avg_first_20, selected_frames), dim=1)  # Shape [C, 7, H, W]\n",
    "\n",
    "        # Convert from [C, 7, H, W] -> [7, H, W] by removing the channel dimension if necessary\n",
    "        if final_tensor.shape[0] == 1:  # If the first dimension is singleton, remove it\n",
    "            final_tensor = final_tensor.squeeze(0)  # Shape becomes [7, H, W]\n",
    "        else:\n",
    "            final_tensor = final_tensor.squeeze()  # General squeeze to avoid extra dims\n",
    "\n",
    "        # Resize each channel to the target size (e.g., 224x224)\n",
    "        resized_tensor = torch.stack([\n",
    "            TF.resize(final_tensor[i].unsqueeze(0), self.target_size).squeeze(0) for i in range(final_tensor.shape[0])\n",
    "        ]) \n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            resized_tensor = self.transform(resized_tensor)\n",
    "\n",
    "        return resized_tensor, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths data\n",
    "train_dataset_path = 'E:/Datasets/Split/SemiQuant/Training/'\n",
    "val_dataset_path = 'E:/Datasets/Split/SemiQuant/Validation/'\n",
    "test_dataset_path = 'E:/Datasets/Split/SemiQuant/Testing/'\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = PTDataset(root_dir=train_dataset_path, target_size=(224, 224))\n",
    "val_dataset = PTDataset(root_dir=val_dataset_path, target_size=(224, 224))\n",
    "test_dataset = PTDataset(root_dir=test_dataset_path, target_size=(224, 224))\n",
    "\n",
    "#DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0) #errors out for num_worker >0\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "for batch in train_loader:\n",
    "    inputs, labels = batch\n",
    "    print(f\"Batch input shape: {inputs.shape}\")  # Expected [batch_size, 7, 224, 224]\n",
    "    print(f\"Batch labels: {labels}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_model(num_classes=4, input_channels=7):\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    model.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "device = torch.device(\"cpu\") #no gpu available at this time\n",
    "\n",
    "model = get_resnet_model(num_classes=4, input_channels=7).to(device)\n",
    "criterion = nn.CrossEntropyLoss() #Binary only for two catergories?\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # Perform validation after each epoch\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion)\n",
    "print(f\"Final Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), 'resnet_model.pth')\n",
    "print(\"Model saved as resnet_model.pth\")\n",
    "\n",
    "model.load_state_dict(torch.load('resnet_model.pth'))\n",
    "model.eval()\n",
    "print(\"Model loaded for inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_tensor):\n",
    "    model.eval()\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)  # Add batch dimension\n",
    "    output = model(input_tensor)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "    return predicted_class.item()\n",
    "\n",
    "# Example inference on a test sample\n",
    "sample_input, _ = test_dataset[0]\n",
    "prediction = predict(model, sample_input)\n",
    "print(f\"Predicted class: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANSA_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
